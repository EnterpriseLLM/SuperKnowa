{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a5ccb09",
   "metadata": {},
   "source": [
    "# In-context Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6415e3b",
   "metadata": {},
   "source": [
    "## Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c56debc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be64b676",
   "metadata": {},
   "source": [
    "## Example of In-context learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafd2143",
   "metadata": {},
   "source": [
    "This example shows how you can pass a context and get answer from the LLM on WatsonX.AI using In-context learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d278bb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_watsonx_request(question):\n",
    "    \n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': \"Bearer YOUR_API_KEY\",\n",
    "    }\n",
    "    \n",
    "    json_data = {\n",
    "        'model_id': 'google/flan-ul2',\n",
    "        \"inputs\": [\"Answer the question based only on the context below. \\\n",
    "            Context: IBM Cloud Pak for Data offers the IBM Watson Knowledge Catalog service, which provides a number of features to incorporate such policy security, and compliance features and to govern your data. A data steward or administrator can use the IBM Watson Knowledge Catalog to build a governance catalog consisting of terms policies, and rules that can help govern and secure the data. \\\n",
    "            Question: \" + question],        \n",
    "          \"parameters\": {\n",
    "            \"decoding_method\": \"greedy\",\n",
    "            \"min_new_tokens\": 20,\n",
    "            \"max_new_tokens\": 200,\n",
    "            \"beam_width\": 1\n",
    "          }\n",
    "    }\n",
    "\n",
    "\n",
    "    response = requests.post('https://workbench-api.res.ibm.com/v1/generate', headers=headers, json=json_data)\n",
    "    json_response = json.loads(response.content.decode(\"utf-8\"))\n",
    "    return json_response['results'][0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a5da890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'service, which provides a number of features to incorporate such policy security, and compliance features and to govern your data'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_watsonx_request(\"What is Watson Knowledge catalog?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddf8832",
   "metadata": {},
   "source": [
    "## Functions to create app using In-context learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bb8c45",
   "metadata": {},
   "source": [
    "This function gets context and question as input from user and answers the question generated by LLM on WatsonX.AI using In-context learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d6d688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def get_input(prompt=\"Please enter your question: \"):\n",
    "    return input(prompt)\n",
    "\n",
    "def get_context(prompt=\"Please enter the context: \"):\n",
    "    return input(prompt)\n",
    "\n",
    "def process_watsonx_request():\n",
    "    context = get_context()\n",
    "    question = get_input()\n",
    "\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': \"Bearer YOUR_API_KEY\",\n",
    "    }\n",
    "    \n",
    "    json_data = {\n",
    "      \"model_id\": \"google/flan-ul2\",\n",
    "      \"inputs\": [\n",
    "        \"Answer the question based only on the context below.\\\n",
    "         Context: \" + context + \\\n",
    "         \"Question: \" + question\n",
    "      ],\n",
    "      \"parameters\": {\n",
    "        \"decoding_method\": \"greedy\",\n",
    "        \"min_new_tokens\": 20,\n",
    "        \"max_new_tokens\": 200,\n",
    "        \"beam_width\": 1\n",
    "      }\n",
    "    }\n",
    "\n",
    "    response = requests.post('https://workbench-api.res.ibm.com/v1/generate', headers=headers, json=json_data)\n",
    "    json_response = json.loads(response.content.decode(\"utf-8\"))\n",
    "    # print(\"BAM Output: \", json_response['results'][0]['generated_text'])\n",
    "    return json_response['results'][0]['generated_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5ff25c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the context: DataOps is a collaborative data management discipline that focuses on end-to-end data management and the elimination of data silos. There are many DataOps definitions provided by the various thought leaders in this space, such as IBM, Gartner, Eckerson Group, Forbes, and DataKitchen, all of which essentially define it as \\\"the orchestration of people, processes, and technology to accelerate the quick delivery of high-quality data to data users.\\\" Built on software development frameworks such as Agile, DevOps, and Statistical Process Control, DataOps offers the following benefits:\\n\\nDecreases the cycle time in deploying analytical solutions\\nLowers data defects\\nReduces the time required to resolve data defects\\nMinimizes data silos\\n\\nDataOps dimensions\\nThere are three dimensions across which DataOps is executed: people, processes, and technology. It requires the organization of a team to promote collaboration and drive culture change, to identify and develop processes that transform existing data pipelines into DataOps pipelines, and absorb its value and identifying advantageous technical product features in a DataOps technology.\\n\\nThe DataOps team\\nDataOps supports a highly productive and tightly collaborative team that uses automation technology to help deliver efficiency gains. It comprises DataOps managers, such as data engineers, information architects, and DataOps engineers who are responsible for leading the delivery, management, and support of high-quality, mission-ready data at scale.\\n\\nData engineers are responsible for data curation, data cleansing, and data availability.\n",
      "Please enter your question: What constitures a DataOps team?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data engineers, information architects, and DataOps engineers who are responsible for leading the delivery, management, and support of high-quality, mission-ready data at scale'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_watsonx_request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991f6094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
